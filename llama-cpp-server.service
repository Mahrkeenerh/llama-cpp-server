[Unit]
Description=llama.cpp Inference Server
After=network.target

[Service]
Type=simple
User=samo
WorkingDirectory=/home/samo/Data/Programs/AI/llama-cpp-server
ExecStart=/home/samo/Data/Programs/AI/llama-cpp-server/venv/bin/python server.py
Restart=on-failure
RestartSec=10
StandardOutput=journal
StandardError=journal

[Install]
WantedBy=multi-user.target
